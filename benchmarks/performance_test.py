"""
Performance benchmarking script for TaskForge
æµ‹è¯•ä¼˜åŒ–å‰åçš„æ€§èƒ½å¯¹æ¯” - åŒ…å«æœ€æ–°çš„æ€§èƒ½ä¼˜åŒ–
"""

import asyncio
import time
from datetime import datetime, timezone, timedelta
from pathlib import Path
import shutil
from typing import List
import statistics

from taskforge.core.task import Task, TaskStatus, TaskPriority
from taskforge.core.queries import TaskQuery
from taskforge.storage.json_storage import JSONStorage
from taskforge.storage.optimized_storage import OptimizedJSONStorage
from taskforge.utils.performance import get_metrics, clear_metrics


class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""

    def __init__(self, data_dir: str = "./benchmark_data"):
        self.data_dir = Path(data_dir)
        self.storage = None

    async def setup(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        # æ¸…ç†æ—§æ•°æ®
        if self.data_dir.exists():
            shutil.rmtree(self.data_dir)

        # åˆå§‹åŒ–å­˜å‚¨
        self.storage = JSONStorage(str(self.data_dir))
        await self.storage.initialize()
        clear_metrics()

    async def teardown(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        if self.storage:
            await self.storage.cleanup()
        if self.data_dir.exists():
            shutil.rmtree(self.data_dir)

    def create_sample_tasks(self, count: int) -> List[Task]:
        """åˆ›å»ºæ ·æœ¬ä»»åŠ¡"""
        tasks = []
        statuses = list(TaskStatus)
        priorities = list(TaskPriority)

        for i in range(count):
            task = Task(
                title=f"Task {i}",
                description=f"Description for task {i}",
                status=statuses[i % len(statuses)],
                priority=priorities[i % len(priorities)],
                project_id=f"project-{i % 10}",
                assigned_to=f"user-{i % 5}",
                due_date=datetime.now(timezone.utc) + timedelta(days=i % 30)
            )
            tasks.append(task)

        return tasks

    async def benchmark_bulk_create(self, count: int = 1000):
        """æµ‹è¯•æ‰¹é‡åˆ›å»ºæ€§èƒ½"""
        print(f"\nğŸ“ æ‰¹é‡åˆ›å»º {count} ä¸ªä»»åŠ¡...")

        tasks = self.create_sample_tasks(count)

        start_time = time.perf_counter()
        await self.storage.bulk_create_tasks(tasks)
        end_time = time.perf_counter()

        duration = end_time - start_time
        rate = count / duration

        print(f"âœ… å®Œæˆ: {duration:.3f}ç§’")
        print(f"âš¡ é€Ÿç‡: {rate:.1f} tasks/sec")

        return duration, rate

    async def benchmark_search_by_status(self):
        """æµ‹è¯•æŒ‰çŠ¶æ€æŸ¥è¯¢æ€§èƒ½"""
        print(f"\nğŸ” æŒ‰çŠ¶æ€æŸ¥è¯¢...")

        query = TaskQuery(status=[TaskStatus.TODO, TaskStatus.IN_PROGRESS])

        start_time = time.perf_counter()
        results = await self.storage.search_tasks(query, "user-1")
        end_time = time.perf_counter()

        duration = end_time - start_time

        print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªä»»åŠ¡")
        print(f"âš¡ ç”¨æ—¶: {duration*1000:.2f}ms")

        return duration, len(results)

    async def benchmark_search_by_project(self):
        """æµ‹è¯•æŒ‰é¡¹ç›®æŸ¥è¯¢æ€§èƒ½"""
        print(f"\nğŸ“ æŒ‰é¡¹ç›®æŸ¥è¯¢...")

        query = TaskQuery(project_id="project-5")

        start_time = time.perf_counter()
        results = await self.storage.search_tasks(query, "user-1")
        end_time = time.perf_counter()

        duration = end_time - start_time

        print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªä»»åŠ¡")
        print(f"âš¡ ç”¨æ—¶: {duration*1000:.2f}ms")

        return duration, len(results)

    async def benchmark_complex_query(self):
        """æµ‹è¯•å¤åˆæŸ¥è¯¢æ€§èƒ½"""
        print(f"\nğŸ” å¤åˆæŸ¥è¯¢ (çŠ¶æ€+ä¼˜å…ˆçº§+é¡¹ç›®)...")

        query = TaskQuery(
            status=[TaskStatus.TODO],
            priority=[TaskPriority.HIGH, TaskPriority.CRITICAL],
            project_id="project-3"
        )

        start_time = time.perf_counter()
        results = await self.storage.search_tasks(query, "user-1")
        end_time = time.perf_counter()

        duration = end_time - start_time

        print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªä»»åŠ¡")
        print(f"âš¡ ç”¨æ—¶: {duration*1000:.2f}ms")

        return duration, len(results)

    async def benchmark_bulk_update(self, count: int = 500):
        """æµ‹è¯•æ‰¹é‡æ›´æ–°æ€§èƒ½"""
        print(f"\nâœï¸ æ‰¹é‡æ›´æ–° {count} ä¸ªä»»åŠ¡...")

        # è·å–è¦æ›´æ–°çš„ä»»åŠ¡
        query = TaskQuery(limit=count)
        tasks = await self.storage.search_tasks(query, "user-1")

        # æ›´æ–°çŠ¶æ€
        for task in tasks:
            task.status = TaskStatus.DONE

        start_time = time.perf_counter()
        await self.storage.bulk_update_tasks(tasks)
        end_time = time.perf_counter()

        duration = end_time - start_time
        rate = count / duration

        print(f"âœ… å®Œæˆ: {duration:.3f}ç§’")
        print(f"âš¡ é€Ÿç‡: {rate:.1f} updates/sec")

        return duration, rate

    async def benchmark_statistics(self):
        """æµ‹è¯•ç»Ÿè®¡æŸ¥è¯¢æ€§èƒ½"""
        print(f"\nğŸ“Š ç»Ÿè®¡æŸ¥è¯¢...")

        start_time = time.perf_counter()
        stats = await self.storage.get_task_statistics()
        end_time = time.perf_counter()

        duration = end_time - start_time

        print(f"âœ… ç»Ÿè®¡å®Œæˆ")
        print(f"   - æ€»ä»»åŠ¡æ•°: {stats['total_tasks']}")
        print(f"   - å®Œæˆç‡: {stats['completion_rate']*100:.1f}%")
        print(f"âš¡ ç”¨æ—¶: {duration*1000:.2f}ms")

        return duration, stats


class OptimizedPerformanceBenchmark(PerformanceBenchmark):
    """ä¼˜åŒ–ç‰ˆæ€§èƒ½åŸºå‡†æµ‹è¯• - ä½¿ç”¨æœ€æ–°çš„ä¼˜åŒ–å­˜å‚¨"""

    async def setup(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ - ä½¿ç”¨ä¼˜åŒ–å­˜å‚¨"""
        # æ¸…ç†æ—§æ•°æ®
        if self.data_dir.exists():
            shutil.rmtree(self.data_dir)

        # åˆå§‹åŒ–ä¼˜åŒ–å­˜å‚¨
        self.storage = OptimizedJSONStorage(str(self.data_dir), save_delay=0.1)  # æ›´çŸ­çš„å»¶è¿Ÿç”¨äºæµ‹è¯•
        await self.storage.initialize()
        clear_metrics()

    async def benchmark_cache_performance(self):
        """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
        print(f"\nğŸš€ ç¼“å­˜æ€§èƒ½æµ‹è¯•...")

        # ç¬¬ä¸€æ¬¡æŸ¥è¯¢ (ç¼“å­˜æœªå‘½ä¸­)
        query = TaskQuery(status=[TaskStatus.TODO], priority=[TaskPriority.HIGH])

        start_time = time.perf_counter()
        results1 = await self.storage.search_tasks(query, "user-1")
        first_query_time = time.perf_counter() - start_time

        # ç¬¬äºŒæ¬¡ç›¸åŒæŸ¥è¯¢ (ç¼“å­˜å‘½ä¸­)
        start_time = time.perf_counter()
        results2 = await self.storage.search_tasks(query, "user-1")
        second_query_time = time.perf_counter() - start_time

        cache_speedup = first_query_time / second_query_time if second_query_time > 0 else float('inf')

        print(f"âœ… é¦–æ¬¡æŸ¥è¯¢: {first_query_time*1000:.2f}ms (ç¼“å­˜æœªå‘½ä¸­)")
        print(f"âœ… ç¼“å­˜æŸ¥è¯¢: {second_query_time*1000:.2f}ms (ç¼“å­˜å‘½ä¸­)")
        print(f"ğŸš€ ç¼“å­˜åŠ é€Ÿ: {cache_speedup:.1f}x")

        # è·å–ç¼“å­˜ç»Ÿè®¡
        cache_stats = await self.storage.get_cache_stats()
        print(f"ğŸ“Š ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']*100:.1f}%")

        return first_query_time, second_query_time, cache_speedup

    async def benchmark_index_performance(self):
        """æµ‹è¯•ç´¢å¼•æ€§èƒ½"""
        print(f"\nğŸ“ˆ ç´¢å¼•æ€§èƒ½æµ‹è¯•...")

        # æµ‹è¯•çŠ¶æ€ç´¢å¼•æŸ¥è¯¢
        query = TaskQuery(status=[TaskStatus.IN_PROGRESS])

        start_time = time.perf_counter()
        results = await self.storage.search_tasks(query, "user-1")
        indexed_time = time.perf_counter() - start_time

        print(f"âœ… ç´¢å¼•æŸ¥è¯¢æ‰¾åˆ° {len(results)} ä¸ªä»»åŠ¡")
        print(f"âš¡ ç”¨æ—¶: {indexed_time*1000:.2f}ms")

        # è·å–ç´¢å¼•ç»Ÿè®¡
        index_stats = self.storage.get_index_statistics()
        print(f"ğŸ“Š ç´¢å¼•ç»Ÿè®¡:")
        for index_name, size in index_stats.items():
            if index_name.endswith('_size'):
                print(f"   - {index_name}: {size}")

        return indexed_time, len(results)


async def run_comparison_benchmark():
    """è¿è¡Œå¯¹æ¯”åŸºå‡†æµ‹è¯•"""
    print("=" * 80)
    print("ğŸ TaskForge æ€§èƒ½ä¼˜åŒ–å¯¹æ¯”æµ‹è¯•")
    print("=" * 80)

    # æµ‹è¯•å‚æ•°
    task_count = 5000
    bulk_update_count = 1000

    # 1. æµ‹è¯•æ ‡å‡†å­˜å‚¨
    print(f"\nğŸ“Š æ ‡å‡†å­˜å‚¨æ€§èƒ½æµ‹è¯• ({task_count} ä»»åŠ¡)")
    print("-" * 50)

    standard_bench = PerformanceBenchmark("./standard_data")

    try:
        await standard_bench.setup()

        # åˆ›å»ºä»»åŠ¡
        create_time, _ = await standard_bench.benchmark_create_tasks(task_count)

        # æœç´¢æµ‹è¯•
        search_time, _ = await standard_bench.benchmark_search_by_status()
        project_time, _ = await standard_bench.benchmark_search_by_project()
        complex_time, _ = await standard_bench.benchmark_complex_query()

        # æ‰¹é‡æ›´æ–°
        bulk_time, _ = await standard_bench.benchmark_bulk_update(bulk_update_count)

        # ç»Ÿè®¡
        stats_time, _ = await standard_bench.benchmark_statistics()

    finally:
        await standard_bench.teardown()

    # 2. æµ‹è¯•ä¼˜åŒ–å­˜å‚¨
    print(f"\nğŸš€ ä¼˜åŒ–å­˜å‚¨æ€§èƒ½æµ‹è¯• ({task_count} ä»»åŠ¡)")
    print("-" * 50)

    optimized_bench = OptimizedPerformanceBenchmark("./optimized_data")

    try:
        await optimized_bench.setup()

        # åˆ›å»ºä»»åŠ¡
        opt_create_time, _ = await optimized_bench.benchmark_create_tasks(task_count)

        # æœç´¢æµ‹è¯•
        opt_search_time, _ = await optimized_bench.benchmark_search_by_status()
        opt_project_time, _ = await optimized_bench.benchmark_search_by_project()
        opt_complex_time, _ = await optimized_bench.benchmark_complex_query()

        # æ‰¹é‡æ›´æ–°
        opt_bulk_time, _ = await optimized_bench.benchmark_bulk_update(bulk_update_count)

        # ç»Ÿè®¡
        opt_stats_time, _ = await optimized_bench.benchmark_statistics()

        # é¢å¤–çš„ä¼˜åŒ–æµ‹è¯•
        cache_first, cache_second, cache_speedup = await optimized_bench.benchmark_cache_performance()
        index_time, _ = await optimized_bench.benchmark_index_performance()

    finally:
        await optimized_bench.teardown()

    # 3. æ€§èƒ½å¯¹æ¯”æ€»ç»“
    print(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”æ€»ç»“")
    print("=" * 80)

    print(f"{'æ“ä½œ':<15} {'æ ‡å‡†å­˜å‚¨(ms)':<12} {'ä¼˜åŒ–å­˜å‚¨(ms)':<12} {'æ€§èƒ½æå‡':<10}")
    print("-" * 60)

    def calculate_improvement(standard, optimized):
        if standard == 0:
            return float('inf')
        return ((standard - optimized) / standard) * 100

    improvements = {
        'åˆ›å»ºä»»åŠ¡': calculate_improvement(create_time*1000, opt_create_time*1000),
        'çŠ¶æ€æœç´¢': calculate_improvement(search_time*1000, opt_search_time*1000),
        'é¡¹ç›®æœç´¢': calculate_improvement(project_time*1000, opt_project_time*1000),
        'å¤æ‚æŸ¥è¯¢': calculate_improvement(complex_time*1000, opt_complex_time*1000),
        'æ‰¹é‡æ›´æ–°': calculate_improvement(bulk_time*1000, opt_bulk_time*1000),
        'ç»Ÿè®¡æŸ¥è¯¢': calculate_improvement(stats_time*1000, opt_stats_time*1000),
    }

    for operation, improvement in improvements.items():
        if operation == 'åˆ›å»ºä»»åŠ¡':
            print(f"{operation:<15} {create_time*1000:<12.2f} {opt_create_time*1000:<12.2f} {improvement:>+7.1f}%")
        elif operation == 'çŠ¶æ€æœç´¢':
            print(f"{operation:<15} {search_time*1000:<12.2f} {opt_search_time*1000:<12.2f} {improvement:>+7.1f}%")
        elif operation == 'é¡¹ç›®æœç´¢':
            print(f"{operation:<15} {project_time*1000:<12.2f} {opt_project_time*1000:<12.2f} {improvement:>+7.1f}%")
        elif operation == 'å¤æ‚æŸ¥è¯¢':
            print(f"{operation:<15} {complex_time*1000:<12.2f} {opt_complex_time*1000:<12.2f} {improvement:>+7.1f}%")
        elif operation == 'æ‰¹é‡æ›´æ–°':
            print(f"{operation:<15} {bulk_time*1000:<12.2f} {opt_bulk_time*1000:<12.2f} {improvement:>+7.1f}%")
        elif operation == 'ç»Ÿè®¡æŸ¥è¯¢':
            print(f"{operation:<15} {stats_time*1000:<12.2f} {opt_stats_time*1000:<12.2f} {improvement:>+7.1f}%")

    print("\nğŸš€ ä¼˜åŒ–ç‰¹æ€§:")
    print(f"   âœ… å»¶è¿Ÿå†™å…¥æœºåˆ¶: å‡å°‘ç£ç›˜I/O")
    print(f"   âœ… å¤šçº§ç´¢å¼•ç³»ç»Ÿ: åŠ é€ŸæŸ¥è¯¢æ€§èƒ½")
    print(f"   âœ… æ™ºèƒ½ç¼“å­˜: ç¼“å­˜åŠ é€Ÿ {cache_speedup:.1f}x")
    print(f"   âœ… æ‰¹é‡æ“ä½œä¼˜åŒ–")
    print(f"   âœ… å¼‚æ­¥å¹¶å‘å¤„ç†")

    # è®¡ç®—å¹³å‡æ€§èƒ½æå‡
    avg_improvement = statistics.mean([imp for imp in improvements.values() if imp != float('inf')])
    print(f"\nğŸ¯ å¹³å‡æ€§èƒ½æå‡: {avg_improvement:+.1f}%")

    if avg_improvement > 50:
        print("ğŸ† æ€§èƒ½ä¼˜åŒ–æ•ˆæœæ˜¾è‘—ï¼")


if __name__ == "__main__":
    import sys

    async def main():
        if len(sys.argv) > 1 and sys.argv[1] == "--compare":
            # è¿è¡Œå¯¹æ¯”æµ‹è¯•
            await run_comparison_benchmark()
        else:
            # è¿è¡Œå•ç‹¬çš„æ ‡å‡†æµ‹è¯•
            bench = PerformanceBenchmark()

            try:
                await bench.run_full_benchmark()
            finally:
                await bench.teardown()

    # è¿è¡Œæµ‹è¯•
    asyncio.run(main())
